import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import matplotlib.pyplot as plt

# 1. Import and preprocess the dataset.
# Assuming the dataset is in a CSV file named 'house_price_dataset.csv'
# You might need to adjust the preprocessing steps based on your specific dataset.
try:
    df = pd.read_csv('house_price_dataset.csv')
except FileNotFoundError:
    print("Error: 'house_price_dataset.csv' not found. Please replace with your dataset file.")
    exit()

# Example preprocessing: Handling missing values (replace with mean) and selecting features/target
# Replace 'target_column' and 'feature_columns' with actual column names from your dataset
if 'target_column' not in df.columns or 'feature_columns' not in df.columns:
    print("Error: Please replace 'target_column' and 'feature_columns' with actual column names.")
    exit()

df = df.fillna(df.mean())
X = df[['feature_columns']] # Use double brackets to keep X as a DataFrame
y = df['target_column']

# 2. Split data into train-test sets.
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 3. Fit a Linear Regression model using sklearn.linear_model.
model = LinearRegression()
model.fit(X_train, y_train)

# Predict on the test set
y_pred = model.predict(X_test)

# 4. Evaluate model using MAE, MSE, R².
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Mean Absolute Error (MAE): {mae}')
print(f'Mean Squared Error (MSE): {mse}')
print(f'R-squared (R²): {r2}')

# 5. Plot regression line and interpret coefficients.
# This plotting example is for simple linear regression (one feature).
# For multiple linear regression, visualizing all dimensions at once is not straightforward.
if X.shape[1] == 1:
    plt.scatter(X_test, y_test, color='blue')
    plt.plot(X_test, y_pred, color='red', linewidth=2)
    plt.xlabel('Feature') # Replace with your feature name
    plt.ylabel('Target') # Replace with your target name
    plt.title('Linear Regression')
    plt.show()

    # Interpret coefficients
    print(f'Intercept: {model.intercept_}')
    print(f'Coefficient: {model.coef_[0]}') # For simple linear regression
elif X.shape[1] > 1:
    # Interpret coefficients for multiple linear regression
    print(f'Intercept: {model.intercept_}')
    print('Coefficients:')
    for i, col in enumerate(X.columns):
        print(f'{col}: {model.coef_[i]}')
